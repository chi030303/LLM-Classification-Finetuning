import pandas as pd
import numpy as np
from sklearn.metrics import log_loss
from scipy.optimize import minimize

# 1. åŠ è½½æ‰€æœ‰æ¨¡å‹çš„ OOF é¢„æµ‹
# è¿™äº›æ˜¯ä½  Stage 2 è®­ç»ƒå®Œç”Ÿæˆçš„ï¼Œæˆ–è€…æ˜¯ Stage 1 çš„ OOF
print("Loading OOF predictions...")

# DeBERTa (Stage 1)
oof_deb = pd.read_csv("data/processed/oof_deberta_v3_large.csv")
p_deb = oof_deb[['pred_a', 'pred_b', 'pred_tie']].values

# LightGBM (Stage 2) - å‡è®¾ä½ ä¿å­˜äº†
# å¦‚æœè¿˜æ²¡ä¿å­˜ï¼Œè¯·å» train_stacking.py æŠŠ lgb_oof å­˜ä¸‹æ¥
oof_lgb = pd.read_csv("outputs/stacking_models/oof_lgbm.csv") 
p_lgb = oof_lgb[['pred_a', 'pred_b', 'pred_tie']].values

# XGBoost (Stage 2)
oof_xgb = pd.read_csv("outputs/stacking_models/oof_xgboost.csv")
p_xgb = oof_xgb[['pred_a', 'pred_b', 'pred_tie']].values

# çœŸå®æ ‡ç­¾
y_true = oof_deb[['winner_model_a', 'winner_model_b', 'winner_tie']].idxmax(axis=1).map({
    'winner_model_a': 0, 'winner_model_b': 1, 'winner_tie': 2
}).values

# 2. å®šä¹‰ç›®æ ‡å‡½æ•°
# weights = [w_deb, w_lgb, w_xgb]
def log_loss_func(weights):
    # å½’ä¸€åŒ–æƒé‡ï¼Œç¡®ä¿å’Œä¸º1
    final_weights = weights / np.sum(weights)
    
    # åŠ æƒå¹³å‡
    p_final = (final_weights[0] * p_deb + 
               final_weights[1] * p_lgb + 
               final_weights[2] * p_xgb)
    
    # ç¨å¾®æˆªæ–­é˜²æ­¢ log(0)
    p_final = np.clip(p_final, 1e-15, 1-1e-15)
    
    return log_loss(y_true, p_final)

# 3. æ±‚è§£æœ€ä½³æƒé‡
print("ğŸ” Optimizing Ensemble Weights...")
# åˆå§‹æƒé‡ [0.33, 0.33, 0.33]
init_guess = [1/3, 1/3, 1/3] 
# çº¦æŸï¼šæƒé‡åœ¨ 0-1 ä¹‹é—´
bounds = [(0, 1), (0, 1), (0, 1)]
# çº¦æŸï¼šæƒé‡ä¹‹å’Œä¸º 1
constraints = ({'type': 'eq', 'fun': lambda w: 1 - sum(w)})

res = minimize(
    log_loss_func, 
    init_guess, 
    method='SLSQP', 
    bounds=bounds, 
    constraints=constraints
)

best_weights = res.x / np.sum(res.x)
print("-" * 30)
print(f"ğŸ† Optimization Success: {res.success}")
print(f"ğŸ“‰ Best Ensemble LogLoss: {res.fun:.5f}")
print("-" * 30)
print(f"Weights Distribution:")
print(f"  DeBERTa: {best_weights[0]:.4f}")
print(f"  LightGBM: {best_weights[1]:.4f}")
print(f"  XGBoost:  {best_weights[2]:.4f}")
print("-" * 30)

# 4. å•ç‹¬å¯¹æ¯”
print("Individual Scores:")
print(f"  DeBERTa Only: {log_loss(y_true, p_deb):.5f}")
print(f"  LightGBM Only: {log_loss(y_true, p_lgb):.5f}")
print(f"  XGBoost Only:  {log_loss(y_true, p_xgb):.5f}")